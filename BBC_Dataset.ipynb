{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjg3adM2G67HDNuhzrTVkM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Poorya0071/NLP_TensorFlow/blob/main/BBC_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BBC Text news classification based on 5 categories"
      ],
      "metadata": {
        "id": "If5l7PklCDqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n"
      ],
      "metadata": {
        "id": "dSTYeIu02SLP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"bbc-text.csv.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "x64AmGyu02oY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = pd.read_csv('/content/bbc-text.csv')"
      ],
      "metadata": {
        "id": "0PKaFNCK2MNx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "U8ktEeFy2QVx",
        "outputId": "772678e8-e55f-42e3-8eb6-4d7db028454f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        category                                               text\n",
              "0           tech  tv future in the hands of viewers with home th...\n",
              "1       business  worldcom boss  left books alone  former worldc...\n",
              "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
              "3          sport  yeading face newcastle in fa cup premiership s...\n",
              "4  entertainment  ocean s twelve raids box office ocean s twelve..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-afa6b3ea-0c20-4ef8-82d2-3bf3e2d8e43d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afa6b3ea-0c20-4ef8-82d2-3bf3e2d8e43d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-afa6b3ea-0c20-4ef8-82d2-3bf3e2d8e43d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-afa6b3ea-0c20-4ef8-82d2-3bf3e2d8e43d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOq56fle2gsa",
        "outputId": "7f2152e3-e167-4967-8a9f-67d5417f1e3a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2225 entries, 0 to 2224\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   category  2225 non-null   object\n",
            " 1   text      2225 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 34.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check the Data imbalance "
      ],
      "metadata": {
        "id": "AwbFf4-WCLxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['category'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SZK3wdn2nMF",
        "outputId": "3ad80543-c5da-4835-d03d-590f719e5dd2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sport            511\n",
              "business         510\n",
              "politics         417\n",
              "tech             401\n",
              "entertainment    386\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Dataset "
      ],
      "metadata": {
        "id": "vkR5unhCCQPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(data[\"text\"].to_numpy(),\n",
        "                                                                            data['category'].to_numpy(),\n",
        "                                                                            test_size=0.15, # dedicate 10% of samples to validation set\n",
        "                                                                            random_state=42)"
      ],
      "metadata": {
        "id": "ZEYHu-pq26il"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Use OneHotEncoder to convert string labels to numbers"
      ],
      "metadata": {
        "id": "ujnwXv1sCTI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_labels.reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_labels.reshape(-1, 1))\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_one_hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul1hfldc3XTQ",
        "outputId": "e915b122-1f8c-4880-d85a-409bff1a218d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "val_labels_encoded = label_encoder.transform(val_labels)\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjv9FS_L3lTY",
        "outputId": "7e09c4c8-48c7-4cf0-e2d6-c204c10facf2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 3, ..., 4, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SKlearn Baseline mode"
      ],
      "metadata": {
        "id": "RrR6NFF_Cbo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6-Q0eHn3y2g",
        "outputId": "a8c3b37b-580e-48b9-9dd5-3a2045f37088"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_score = model_0.score(val_sentences, val_labels_encoded)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn1JFYOq34Om",
        "outputId": "e217ab11-2ac1-4985-9bd3-318d4159a3f0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 94.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YS_P-KJ4PkY",
        "outputId": "c0c7eff6-9caf-4dac-8951-5d9324cab5b4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "387"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TextVector and Embedding"
      ],
      "metadata": {
        "id": "ehaskeU3CmoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab_length = 60000 # max number of words to have in our vocabulary\n",
        "max_length = 387 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "BOu2As6n4PfL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "MdBDVG3S4nGq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=max_length, # how long is each input\n",
        "                             name=\"embedding_1\") \n",
        "\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoADBdt44rnt",
        "outputId": "b5fded8c-574c-4069-b299-e0d643ad28ca"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.embedding.Embedding at 0x7fa373f409d0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM model"
      ],
      "metadata": {
        "id": "nvmMFjexCjCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_2\")\n",
        "\n",
        "\n",
        "# Create LSTM model\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_2_embedding(x)\n",
        "print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
        "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
        "print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
        "outputs = layers.Dense(5, activation=\"softmax\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")\n",
        "\n",
        "# Compile model\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit model\n",
        "model_2_history = model_2.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels_one_hot,\n",
        "                              steps_per_epoch=len(train_sentences)//16,\n",
        "                              epochs=15,\n",
        "                              validation_data=(val_sentences, val_labels_one_hot),\n",
        "                              validation_steps=len(val_sentences)\n",
        "                              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3NtTInN4Dzp",
        "outputId": "fb87bd62-3c5c-4025-af5a-6d8af61622bf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 387, 128)\n",
            "(None, 64)\n",
            "Epoch 1/15\n",
            "118/118 [==============================] - 26s 212ms/step - loss: 1.5326 - accuracy: 0.3026 - val_loss: 1.4513 - val_accuracy: 0.3353\n",
            "Epoch 2/15\n",
            "118/118 [==============================] - 25s 216ms/step - loss: 1.4744 - accuracy: 0.4114 - val_loss: 1.4643 - val_accuracy: 0.3952\n",
            "Epoch 3/15\n",
            "118/118 [==============================] - 25s 209ms/step - loss: 1.3254 - accuracy: 0.4134 - val_loss: 1.2096 - val_accuracy: 0.4042\n",
            "Epoch 4/15\n",
            "118/118 [==============================] - 24s 208ms/step - loss: 1.1611 - accuracy: 0.5118 - val_loss: 1.3998 - val_accuracy: 0.3922\n",
            "Epoch 5/15\n",
            "118/118 [==============================] - 28s 241ms/step - loss: 1.1593 - accuracy: 0.5314 - val_loss: 1.3181 - val_accuracy: 0.4102\n",
            "Epoch 6/15\n",
            "118/118 [==============================] - 27s 225ms/step - loss: 0.9828 - accuracy: 0.5710 - val_loss: 1.2061 - val_accuracy: 0.5419\n",
            "Epoch 7/15\n",
            "118/118 [==============================] - 29s 246ms/step - loss: 0.9924 - accuracy: 0.5534 - val_loss: 1.2521 - val_accuracy: 0.4341\n",
            "Epoch 8/15\n",
            "118/118 [==============================] - 24s 208ms/step - loss: 0.8519 - accuracy: 0.6041 - val_loss: 1.1160 - val_accuracy: 0.5599\n",
            "Epoch 9/15\n",
            "118/118 [==============================] - 25s 214ms/step - loss: 0.9473 - accuracy: 0.6071 - val_loss: 1.1947 - val_accuracy: 0.4611\n",
            "Epoch 10/15\n",
            "118/118 [==============================] - 25s 209ms/step - loss: 0.7873 - accuracy: 0.6302 - val_loss: 1.0953 - val_accuracy: 0.5659\n",
            "Epoch 11/15\n",
            "118/118 [==============================] - 25s 209ms/step - loss: 0.7092 - accuracy: 0.6598 - val_loss: 1.0548 - val_accuracy: 0.6108\n",
            "Epoch 12/15\n",
            "118/118 [==============================] - 25s 216ms/step - loss: 0.7366 - accuracy: 0.6458 - val_loss: 1.0101 - val_accuracy: 0.6048\n",
            "Epoch 13/15\n",
            "118/118 [==============================] - 25s 209ms/step - loss: 0.7017 - accuracy: 0.6829 - val_loss: 1.2068 - val_accuracy: 0.5030\n",
            "Epoch 14/15\n",
            "118/118 [==============================] - 25s 210ms/step - loss: 0.6800 - accuracy: 0.6914 - val_loss: 1.0898 - val_accuracy: 0.5509\n",
            "Epoch 15/15\n",
            " 28/118 [======>.......................] - ETA: 15s - loss: 0.5991 - accuracy: 0.7063"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1770 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r118/118 [==============================] - 9s 73ms/step - loss: 0.5991 - accuracy: 0.7063 - val_loss: 0.9904 - val_accuracy: 0.5958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning"
      ],
      "metadata": {
        "id": "8UxJe0FaCgFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")"
      ],
      "metadata": {
        "id": "m4NswrdL5HHF"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature extractor model using TF Hub layer\n",
        "inputs = layers.Input(shape=[], dtype=tf.string)\n",
        "pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize text and create embedding\n",
        "x = layers.Dense(128, activation=\"relu\")(pretrained_embedding) # add a fully connected layer on top of the embedding\n",
        "# Note: you could add more layers here if you wanted to\n",
        "outputs = layers.Dense(5, activation=\"softmax\")(x) # create the output layer\n",
        "model_2 = tf.keras.Model(inputs=inputs,\n",
        "                        outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "WkP_KbL49q3M"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_history = model_2.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels_one_hot,\n",
        "                              steps_per_epoch=len(train_sentences),\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels_one_hot),\n",
        "                              validation_steps=len(val_sentences)\n",
        "                              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbLq0gp59vlM",
        "outputId": "3a612309-8e27-429c-89a6-c2985ab0789f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1891/1891 [==============================] - 13s 6ms/step - loss: 0.2330 - accuracy: 0.9434 - val_loss: 0.0761 - val_accuracy: 0.9731\n",
            "Epoch 2/5\n",
            "1891/1891 [==============================] - 13s 7ms/step - loss: 0.0420 - accuracy: 0.9857 - val_loss: 0.0605 - val_accuracy: 0.9820\n",
            "Epoch 3/5\n",
            "1891/1891 [==============================] - 12s 6ms/step - loss: 0.0184 - accuracy: 0.9952 - val_loss: 0.0775 - val_accuracy: 0.9760\n",
            "Epoch 4/5\n",
            "1891/1891 [==============================] - 14s 7ms/step - loss: 0.0172 - accuracy: 0.9931 - val_loss: 0.0659 - val_accuracy: 0.9701\n",
            "Epoch 5/5\n",
            "1891/1891 [==============================] - 12s 6ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0633 - val_accuracy: 0.9790\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.evaluate(val_sentences, val_labels_one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ovfs5xgr958k",
        "outputId": "1384253c-3ebc-4732-cf78-39a8598d476c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 1s 59ms/step - loss: 0.0633 - accuracy: 0.9790\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06329511851072311, 0.9790419340133667]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction on a text from the Internet"
      ],
      "metadata": {
        "id": "bsvK8bpUC6UJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = \"Today we present 20 players whose names you'll hear about in trade rumours over the next seven weeks. We'll update this list as we go and situations change, to reflect injuries, news and other developments that may change the landscape.\"\n",
        "model_2.predict([sample_data])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JA7lAtPC975",
        "outputId": "3be2b6d9-e93b-487b-b2ee-6cec0e3bf5af"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 462ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04932658, 0.00219719, 0.00186718, 0.8588744 , 0.08773471]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usGqQMqEDyhS",
        "outputId": "4716b40f-d9d2-495f-b78f-73df9d6cd0a6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, array(['business', 'entertainment', 'politics', 'sport', 'tech'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The prediction tells us the sample sentence belongs to Sport category with 86%"
      ],
      "metadata": {
        "id": "9HKDNtT2EIK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dense Model"
      ],
      "metadata": {
        "id": "yqQmxozcKhWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "-XnSKBSEBEc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_2\")\n",
        "\n",
        "\n",
        "# Create LSTM model\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "print(x.shape)\n",
        "\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "x = layers.Dense(64, activation='relu')(x) \n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "print(x.shape)\n",
        "outputs = layers.Dense(5, activation=\"softmax\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")\n",
        "\n",
        "# Compile model\n",
        "model_3.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit model\n",
        "model_3_history = model_3.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels_one_hot,\n",
        "                              steps_per_epoch=len(train_sentences),\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels_one_hot),\n",
        "                              validation_steps=len(val_sentences)\n",
        "                              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvUobFGxJNIB",
        "outputId": "2b27e987-cd3d-423a-9517-09e0305d3dcb"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 387, 128)\n",
            "(None, 64)\n",
            "Epoch 1/5\n",
            "1891/1891 [==============================] - 91s 48ms/step - loss: 0.5906 - accuracy: 0.7842 - val_loss: 0.1434 - val_accuracy: 0.9521\n",
            "Epoch 2/5\n",
            "1891/1891 [==============================] - 91s 48ms/step - loss: 0.0340 - accuracy: 0.9910 - val_loss: 0.1018 - val_accuracy: 0.9701\n",
            "Epoch 3/5\n",
            "1891/1891 [==============================] - 88s 47ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9671\n",
            "Epoch 4/5\n",
            "1891/1891 [==============================] - 88s 47ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0681 - val_accuracy: 0.9731\n",
            "Epoch 5/5\n",
            "1891/1891 [==============================] - 87s 46ms/step - loss: 1.7886e-04 - accuracy: 1.0000 - val_loss: 0.0711 - val_accuracy: 0.9731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.predict([sample_data])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smfDRfYoKsK8",
        "outputId": "118bacc3-b6fd-4338-c5e7-cb2d3239e810"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 136ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0757347 , 0.13835402, 0.01345917, 0.77161586, 0.00083634]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "The transfer learning embedding layer and Dense model work very well and beats the basemodel."
      ],
      "metadata": {
        "id": "Vag9HSJ9Crpd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j7bzGKPQJiTC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}